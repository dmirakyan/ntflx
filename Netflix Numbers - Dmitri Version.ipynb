{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "11ec36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from scipy.sparse import hstack\n",
    "# from matplotlib import pyplot as plt\n",
    "# import eli5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "24374fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "stemmer = LancasterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc84330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>titlereleased</th>\n",
       "      <th>image_landscape</th>\n",
       "      <th>image_portrait</th>\n",
       "      <th>rating</th>\n",
       "      <th>quality</th>\n",
       "      <th>actors</th>\n",
       "      <th>director</th>\n",
       "      <th>category</th>\n",
       "      <th>imdb</th>\n",
       "      <th>runtime</th>\n",
       "      <th>netflixid</th>\n",
       "      <th>date_released</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Alive</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.whats-on-netflix.com/wp-content/up...</td>\n",
       "      <td>https://www.whats-on-netflix.com/wp-content/up...</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>Yoo Ah-in, Park Shin-hye</td>\n",
       "      <td>Cho Il</td>\n",
       "      <td>Horror, Zombie, Korean</td>\n",
       "      <td>6.2/10</td>\n",
       "      <td>98 mins</td>\n",
       "      <td>81240831</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>As a grisly virus rampages a city, a lone man ...</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#AnneFrank - Parallel Stories</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>Helen Mirren, Gengher Gatti</td>\n",
       "      <td>Sabina Fedeli, Anna Migotto</td>\n",
       "      <td>Documentary</td>\n",
       "      <td></td>\n",
       "      <td>94 mins</td>\n",
       "      <td>81264660</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Through her diary, Anne Frank's story is retol...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#cats_the_mewvie</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td></td>\n",
       "      <td>Michael Margolis</td>\n",
       "      <td></td>\n",
       "      <td>5.2/10</td>\n",
       "      <td>89 minutes</td>\n",
       "      <td>81218137</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>This pawesome documentary explores how our fel...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#FriendButMarried</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>Adipati Dolken, Vanesha Prescilla, Refal Hady,...</td>\n",
       "      <td>Rako Prijanto</td>\n",
       "      <td>Biography, Drama</td>\n",
       "      <td>7.1/10</td>\n",
       "      <td>102 min</td>\n",
       "      <td>81260630</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>Pining for his high school crush for years, a ...</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#FriendButMarried 2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>Adipati Dolken, Mawar Eva de Jongh, Vonny Corn...</td>\n",
       "      <td>Rako Prijanto</td>\n",
       "      <td>Biography, Drama, Romance</td>\n",
       "      <td></td>\n",
       "      <td>104 mins</td>\n",
       "      <td>81260637</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>As Ayu and Ditto finally transition from best ...</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title   type titlereleased  \\\n",
       "0                         #Alive   Movie          2020   \n",
       "1  #AnneFrank - Parallel Stories   Movie          2019   \n",
       "2                #cats_the_mewvie  Movie          2020   \n",
       "3              #FriendButMarried   Movie          2018   \n",
       "4            #FriendButMarried 2   Movie          2020   \n",
       "\n",
       "                                     image_landscape  \\\n",
       "0  https://www.whats-on-netflix.com/wp-content/up...   \n",
       "1  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   \n",
       "2  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...   \n",
       "3  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   \n",
       "4  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   \n",
       "\n",
       "                                      image_portrait rating  quality  \\\n",
       "0  https://www.whats-on-netflix.com/wp-content/up...  TV-MA  SuperHD   \n",
       "1  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...  TV-14  SuperHD   \n",
       "2  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...  TV-14  SuperHD   \n",
       "3  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   TV-G  SuperHD   \n",
       "4  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   TV-G  SuperHD   \n",
       "\n",
       "                                              actors  \\\n",
       "0                           Yoo Ah-in, Park Shin-hye   \n",
       "1                        Helen Mirren, Gengher Gatti   \n",
       "2                                                      \n",
       "3  Adipati Dolken, Vanesha Prescilla, Refal Hady,...   \n",
       "4  Adipati Dolken, Mawar Eva de Jongh, Vonny Corn...   \n",
       "\n",
       "                      director                   category    imdb     runtime  \\\n",
       "0                       Cho Il     Horror, Zombie, Korean  6.2/10     98 mins   \n",
       "1  Sabina Fedeli, Anna Migotto                Documentary             94 mins   \n",
       "2             Michael Margolis                             5.2/10  89 minutes   \n",
       "3                Rako Prijanto           Biography, Drama  7.1/10     102 min   \n",
       "4                Rako Prijanto  Biography, Drama, Romance            104 mins   \n",
       "\n",
       "   netflixid date_released                                        description  \\\n",
       "0   81240831    2020-09-08  As a grisly virus rampages a city, a lone man ...   \n",
       "1   81264660    2020-07-01  Through her diary, Anne Frank's story is retol...   \n",
       "2   81218137    2020-02-05  This pawesome documentary explores how our fel...   \n",
       "3   81260630    2020-05-22  Pining for his high school crush for years, a ...   \n",
       "4   81260637    2020-06-28  As Ayu and Ditto finally transition from best ...   \n",
       "\n",
       "     language  \n",
       "0      Korean  \n",
       "1     English  \n",
       "2     English  \n",
       "3  Indonesian  \n",
       "4  Indonesian  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = requests.get('https://www.whats-on-netflix.com/wp-content/plugins/whats-on-netflix/json/movie.json?_=1619550477680')\n",
    "tv = requests.get('https://www.whats-on-netflix.com/wp-content/plugins/whats-on-netflix/json/tv.json?_=1619550201106')\n",
    "\n",
    "movie_df = pd.read_json(movies.content)\n",
    "tv_df = pd.read_json(tv.content)\n",
    "content = pd.concat([movie_df,tv_df]).reset_index(drop=True)\n",
    "content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840ea02",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b70c8a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>titlereleased</th>\n",
       "      <th>image_landscape</th>\n",
       "      <th>image_portrait</th>\n",
       "      <th>rating</th>\n",
       "      <th>quality</th>\n",
       "      <th>actors</th>\n",
       "      <th>director</th>\n",
       "      <th>category</th>\n",
       "      <th>imdb</th>\n",
       "      <th>runtime</th>\n",
       "      <th>netflixid</th>\n",
       "      <th>date_released</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Alive</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.whats-on-netflix.com/wp-content/up...</td>\n",
       "      <td>https://www.whats-on-netflix.com/wp-content/up...</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Yoo Ah-in,  Park Shin-hye]</td>\n",
       "      <td>Cho Il</td>\n",
       "      <td>[horror, zombie, korean]</td>\n",
       "      <td>6.2/10</td>\n",
       "      <td>98 mins</td>\n",
       "      <td>81240831</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>As a grisly virus rampages a city, a lone man ...</td>\n",
       "      <td>Korean</td>\n",
       "      <td>[gris, vir, ramp, city, lon, man, stay, lock, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#AnneFrank - Parallel Stories</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Helen Mirren,  Gengher Gatti]</td>\n",
       "      <td>Sabina Fedeli, Anna Migotto</td>\n",
       "      <td>[documentary]</td>\n",
       "      <td></td>\n",
       "      <td>94 mins</td>\n",
       "      <td>81264660</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Through her diary, Anne Frank's story is retol...</td>\n",
       "      <td>English</td>\n",
       "      <td>[diary, an, frank, story, retold, alongsid, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#cats_the_mewvie</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[]</td>\n",
       "      <td>Michael Margolis</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.2/10</td>\n",
       "      <td>89 minutes</td>\n",
       "      <td>81218137</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>This pawesome documentary explores how our fel...</td>\n",
       "      <td>English</td>\n",
       "      <td>[pawesom, docu, expl, felin, friend, becam, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#FriendButMarried</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Adipati Dolken,  Vanesha Prescilla,  Refal Ha...</td>\n",
       "      <td>Rako Prijanto</td>\n",
       "      <td>[biography, drama]</td>\n",
       "      <td>7.1/10</td>\n",
       "      <td>102 min</td>\n",
       "      <td>81260630</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>Pining for his high school crush for years, a ...</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>[pin, high, school, crush, year, young, man, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#FriendButMarried 2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Adipati Dolken,  Mawar Eva de Jongh,  Vonny C...</td>\n",
       "      <td>Rako Prijanto</td>\n",
       "      <td>[biography, drama, romance]</td>\n",
       "      <td></td>\n",
       "      <td>104 mins</td>\n",
       "      <td>81260637</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>As Ayu and Ditto finally transition from best ...</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>[ayu, ditto, fin, transit, best, friend, newly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title   type titlereleased  \\\n",
       "0                         #Alive   Movie          2020   \n",
       "1  #AnneFrank - Parallel Stories   Movie          2019   \n",
       "2                #cats_the_mewvie  Movie          2020   \n",
       "3              #FriendButMarried   Movie          2018   \n",
       "4            #FriendButMarried 2   Movie          2020   \n",
       "\n",
       "                                     image_landscape  \\\n",
       "0  https://www.whats-on-netflix.com/wp-content/up...   \n",
       "1  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   \n",
       "2  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...   \n",
       "3  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   \n",
       "4  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   \n",
       "\n",
       "                                      image_portrait rating  quality  \\\n",
       "0  https://www.whats-on-netflix.com/wp-content/up...  TV-MA  SuperHD   \n",
       "1  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...  TV-14  SuperHD   \n",
       "2  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...  TV-14  SuperHD   \n",
       "3  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   TV-G  SuperHD   \n",
       "4  https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   TV-G  SuperHD   \n",
       "\n",
       "                                              actors  \\\n",
       "0                        [Yoo Ah-in,  Park Shin-hye]   \n",
       "1                     [Helen Mirren,  Gengher Gatti]   \n",
       "2                                                 []   \n",
       "3  [Adipati Dolken,  Vanesha Prescilla,  Refal Ha...   \n",
       "4  [Adipati Dolken,  Mawar Eva de Jongh,  Vonny C...   \n",
       "\n",
       "                      director                     category    imdb  \\\n",
       "0                       Cho Il     [horror, zombie, korean]  6.2/10   \n",
       "1  Sabina Fedeli, Anna Migotto                [documentary]           \n",
       "2             Michael Margolis                           []  5.2/10   \n",
       "3                Rako Prijanto           [biography, drama]  7.1/10   \n",
       "4                Rako Prijanto  [biography, drama, romance]           \n",
       "\n",
       "      runtime  netflixid date_released  \\\n",
       "0     98 mins   81240831    2020-09-08   \n",
       "1     94 mins   81264660    2020-07-01   \n",
       "2  89 minutes   81218137    2020-02-05   \n",
       "3     102 min   81260630    2020-05-22   \n",
       "4    104 mins   81260637    2020-06-28   \n",
       "\n",
       "                                         description    language  \\\n",
       "0  As a grisly virus rampages a city, a lone man ...      Korean   \n",
       "1  Through her diary, Anne Frank's story is retol...     English   \n",
       "2  This pawesome documentary explores how our fel...     English   \n",
       "3  Pining for his high school crush for years, a ...  Indonesian   \n",
       "4  As Ayu and Ditto finally transition from best ...  Indonesian   \n",
       "\n",
       "                                   description_clean  \n",
       "0  [gris, vir, ramp, city, lon, man, stay, lock, ...  \n",
       "1  [diary, an, frank, story, retold, alongsid, fi...  \n",
       "2  [pawesom, docu, expl, felin, friend, becam, on...  \n",
       "3  [pin, high, school, crush, year, young, man, p...  \n",
       "4  [ayu, ditto, fin, transit, best, friend, newly...  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn columns with comma separated items into lists\n",
    "# content['category'] = content['category'].apply(lambda x: x.split(\",\"))\n",
    "# content['actors'] = content['actors'].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "# Clean up data for tf_idf\n",
    "content[\"description_clean\"] = content['description'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "content[\"description_clean\"] = content[\"description_clean\"].apply(lambda x: x.split(\" \"))\n",
    "content[\"description_clean\"] = content[\"description_clean\"].apply(lambda x: [item.replace(\"'\",' ') for item in x])\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "content[\"description_clean\"] = content[\"description_clean\"].apply(lambda x: [item for item in x if item not in stoplist])\n",
    "\n",
    "content[\"description_clean\"] = content[\"description_clean\"].apply(lambda x: [item for item in x if item != \"\"])\n",
    "\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "content[\"description_clean\"] = content[\"description_clean\"].apply(lambda x: [lem.lemmatize(item) for item in x])\n",
    "\n",
    "lancaster=LancasterStemmer()\n",
    "content[\"description_clean\"] = content[\"description_clean\"].apply(lambda x: [lancaster.stem(item) for item in x])\n",
    "\n",
    "\n",
    "content['category'] = content['category'].apply(lambda x: [item.lower().strip() for item in x])\n",
    "\n",
    "content.description_clean[0:5]\n",
    "\n",
    "\n",
    "content.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2638baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in content[\"description_clean\"] for item in sublist]\n",
    "df = pd.DataFrame(flat_list, columns = ['cat'])\n",
    "df.value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd38cc",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6e23120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>007</th>\n",
       "      <th>009</th>\n",
       "      <th>00s</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100000</th>\n",
       "      <th>102yearold</th>\n",
       "      <th>...</th>\n",
       "      <th>zé</th>\n",
       "      <th>álex</th>\n",
       "      <th>álvaro</th>\n",
       "      <th>ángel</th>\n",
       "      <th>ömer</th>\n",
       "      <th>über</th>\n",
       "      <th>überelit</th>\n",
       "      <th>łukasz</th>\n",
       "      <th>ōara</th>\n",
       "      <th>şeref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5835 rows × 10633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      007  009  00s    1   10  100  1000  10000   100000  102yearold  ...  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "...   ...  ...  ...  ...  ...  ...   ...    ...      ...         ...  ...   \n",
       "5830  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "5831  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "5832  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.29931         0.0  ...   \n",
       "5833  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "5834  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.00000         0.0  ...   \n",
       "\n",
       "       zé  álex  álvaro  ángel  ömer  über  überelit  łukasz  ōara  şeref  \n",
       "0     0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "1     0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "2     0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "3     0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "4     0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "...   ...   ...     ...    ...   ...   ...       ...     ...   ...    ...  \n",
       "5830  0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "5831  0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "5832  0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "5833  0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "5834  0.0   0.0     0.0    0.0   0.0   0.0       0.0     0.0   0.0    0.0  \n",
       "\n",
       "[5835 rows x 10633 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# test = vectorizer.fit_transform(content.description_clean)\n",
    "# test\n",
    "\n",
    "tfIdfTransformer = TfidfTransformer(use_idf=True)\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "wordcount = vectorizer.fit_transform(content.description_clean)\n",
    "tfidf = tfIdfTransformer.fit_transform(wordcount)\n",
    "dense = tfidf.todense()\n",
    "denselist = dense.tolist()\n",
    "freq_df = pd.DataFrame(denselist, columns=vectorizer.get_feature_names())\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7401c78",
   "metadata": {},
   "source": [
    "### One vs rest modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a5e451fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where no categories are present\n",
    "combo_df = content[content.category.astype(str).str.len() > 4]\n",
    "combo_df = combo_df[['category']]\n",
    "combo_df = combo_df.merge(freq_df,left_index=True, right_index=True)\n",
    "combo_df_ovm = combo_df.copy()\n",
    "\n",
    "# Evaluate model on just a single category to start\n",
    "combo_df_ovm.category = combo_df_ovm.category.apply(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9a8ff2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitri.mirakyanopendoor.com/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.28457447, 0.30851064, 0.30053191])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test train split \n",
    "y = combo_df_ovm.pop('category')\n",
    "X = combo_df_ovm\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\n",
    "logit = LogisticRegression(C=1, solver='lbfgs', multi_class='multinomial', random_state=17)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)\n",
    "cv_results = cross_val_score(logit, X_train, y_train, cv=skf, scoring='f1_micro')\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7fcde2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3367768595041322"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)\n",
    "logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "24455215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(random_state=0))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onevsrest = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "onevsrest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "002c4950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.384297520661157"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onevsrest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9dc5989b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-0d444eddb518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Gradient boosting (untuned) did noticeable worse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxgbrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxgbrest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mxgbrest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# overall.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \"\"\"\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'multioutput'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             raise ValueError(\"Multioutput target data is not supported with \"\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    277\u001b[0m         if (not hasattr(y[0], '__array__') and isinstance(y[0], Sequence)\n\u001b[1;32m    278\u001b[0m                 and not isinstance(y[0], str)):\n\u001b[0;32m--> 279\u001b[0;31m             raise ValueError('You appear to be using a legacy multi-label data'\n\u001b[0m\u001b[1;32m    280\u001b[0m                              \u001b[0;34m' representation. Sequence of sequences are no'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                              \u001b[0;34m' longer supported; use a binary array or sparse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "# Gradient boosting (untuned) did noticeable worse.\n",
    "xgbrest = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "xgbrest.fit(X_train, y_train)\n",
    "xgbrest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does setting the threshold actually do?\n",
    "# Why does it run for infinity\n",
    "\n",
    "onevsrest = OneVsRestClassifier(SVC(kernel='linear', probability=True, class_weight=None))\n",
    "onevsrest.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X)\n",
    "# y_pred_prob = onevsrest.predict_proba(X_test)\n",
    "# y_pred_label = (y_pred_prob >= t).astype(int)\n",
    "t=0.3\n",
    "y_pred_prob = onevsrest.predict_proba(X_test)\n",
    "y_pred_label = (y_pred_prob >= t).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# 1 vs rest.\n",
    "# First approach - pick the first category.\n",
    "# New setup - 1 row = 1 y. Multiple categories but multiple rows. \n",
    "# The model will predict the likelihood of being in any of the categories.\n",
    "\n",
    "# Logistic regression is slightly different. \n",
    "# It will create a pair.\n",
    "# It will then aggregate via a method. From all the pairwise models, what is the total likelihood of being.\n",
    "\n",
    "# Alternative\n",
    "# Multi-label category. \n",
    "# Only take the top 300 words in the feature space.\n",
    "# Also only look for the most common categories in the outcome.\n",
    "# Also probably understand how the model you're using work\n",
    "# Example/reference: https://www.kaggle.com/questions-and-answers/66693\n",
    "\n",
    "# Other measures: fake description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89b8bb",
   "metadata": {},
   "source": [
    "## Multi-label classication modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "49f7f959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat        \n",
       "drama          602\n",
       "comedy         429\n",
       "thriller       245\n",
       "action         202\n",
       "documentary    198\n",
       "romance        192\n",
       "animation      165\n",
       "crime          149\n",
       "family         147\n",
       "adventure      116\n",
       "fantasy        107\n",
       "mystery         96\n",
       "horror          88\n",
       "sci-fi          84\n",
       "biography       57\n",
       "music           55\n",
       "kids            50\n",
       "reality-tv      34\n",
       "sport           34\n",
       "musical         34\n",
       "history         34\n",
       "war             33\n",
       "short           21\n",
       "romantic        18\n",
       "animated        18\n",
       "children        17\n",
       "game-show       16\n",
       "stand-up        14\n",
       "nollywood       12\n",
       "christmas       10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by evaluating the quality of the category items\n",
    "\n",
    "flat_list = [item for sublist in combo_df[\"category\"] for item in sublist]\n",
    "df = pd.DataFrame(flat_list, columns = ['cat'])\n",
    "df.value_counts()[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ad663527",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df_mlc = combo_df.copy()\n",
    "\n",
    "y = combo_df_mlc.pop('category')\n",
    "m = MultiLabelBinarizer()\n",
    "y = m.fit_transform(y)\n",
    "X = combo_df_mlc\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "58dfd1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(random_state=1),\n",
       "                      n_jobs=-1)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logit = LogisticRegression(C=1, solver='lbfgs', multi_class='multinomial', random_state=17)\n",
    "# mlc = MultiOutputClassifier(logit)\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "mlc = MultiOutputClassifier(forest,n_jobs=-1)\n",
    "mlc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c7fb6a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05991735537190083"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "482c614b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('animation',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('comedy', 'drama'),\n",
       " ('comedy', 'drama'),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('comedy',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('documentary',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('comedy', 'drama'),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama', 'romance'),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " ('comedy',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama', 'thriller'),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('comedy',),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama', 'romance'),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " ('animation', 'anime'),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('comedy', 'drama'),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('comedy', 'drama'),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('comedy',),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " ('comedy',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('animation',),\n",
       " ('drama',),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('documentary', 'drama'),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " ('documentary',),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('animation',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('drama',),\n",
       " ('drama',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ('comedy', 'drama'),\n",
       " (),\n",
       " ('comedy',),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " (),\n",
       " ()]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = mlc.predict(X_test)\n",
    "o = m.inverse_transform(output)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3d23043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>titlereleased</th>\n",
       "      <th>image_landscape</th>\n",
       "      <th>image_portrait</th>\n",
       "      <th>rating</th>\n",
       "      <th>quality</th>\n",
       "      <th>actors</th>\n",
       "      <th>director</th>\n",
       "      <th>category</th>\n",
       "      <th>imdb</th>\n",
       "      <th>runtime</th>\n",
       "      <th>netflixid</th>\n",
       "      <th>date_released</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>Whose Streets?</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://www.whats-on-netflix.com/wp-content/up...</td>\n",
       "      <td>https://www.whats-on-netflix.com/wp-content/up...</td>\n",
       "      <td>R</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Lezley McSpadden,  Michael Brown Sr.,  David ...</td>\n",
       "      <td>Sabaah Folayan, Damon Davis(co-director)</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>None</td>\n",
       "      <td>102 min</td>\n",
       "      <td>80168085</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>Powered by activists and leaders, this documen...</td>\n",
       "      <td>English</td>\n",
       "      <td>[powered, activist, leader, documentary, follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>Salaakhen</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1975</td>\n",
       "      <td>https://occ-0-114-116.1.nflxso.net/art/7e232/9...</td>\n",
       "      <td>https://occ-0-114-116.1.nflxso.net/art/7e232/9...</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Shashi Kapoor,  Sulakshana Pandit,  Mehmood, ...</td>\n",
       "      <td>A. Salaam</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.3/10</td>\n",
       "      <td>133 minutes</td>\n",
       "      <td>80158479</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>Two close childhood friends take drastically d...</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>[two, close, childhood, friend, take, drastica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Echcharikkai</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/art/8be71...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/art/8be71...</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Sathyaraj,  Varalakshmi Sarathkumar,  Kishore...</td>\n",
       "      <td>Sarjun</td>\n",
       "      <td>[]</td>\n",
       "      <td>6.5/10</td>\n",
       "      <td>126 minutes</td>\n",
       "      <td>81045065</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>After kidnapping a millionaire’s daughter, two...</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>[kidnapping, millionaire, daughter, two, men, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>Girl</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>R</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Katelijne Damen,  Oliver Bodart,  Magali Elal...</td>\n",
       "      <td>Lukas Dhont</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.2/10</td>\n",
       "      <td>105 minutes</td>\n",
       "      <td>81004374</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>Fifteen-year-old ballet dancer Lara faces phys...</td>\n",
       "      <td>French</td>\n",
       "      <td>[fifteenyearold, ballet, dancer, lara, face, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Cook Off</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Tendaiishe Chitima,  Tomas Brickhill,  Chirik...</td>\n",
       "      <td>Tomas Brickhill</td>\n",
       "      <td>[Comedy,  Romance]</td>\n",
       "      <td>6.4/10</td>\n",
       "      <td>101 min</td>\n",
       "      <td>81273196</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Yearning for a better life, a single mother wi...</td>\n",
       "      <td>English</td>\n",
       "      <td>[yearning, better, life, single, mother, passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>The Pixar Story</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2007</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/art/66734...</td>\n",
       "      <td>https://occ-0-1722-1723.1.nflxso.net/art/66734...</td>\n",
       "      <td>G</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Stacy Keach]</td>\n",
       "      <td>Leslie Iwerks</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.8/10</td>\n",
       "      <td>88 minutes</td>\n",
       "      <td>70083532</td>\n",
       "      <td>2018-11-18</td>\n",
       "      <td>Go behind the scenes at Pixar Animation Studio...</td>\n",
       "      <td>English</td>\n",
       "      <td>[go, behind, scene, pixar, animation, studio, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>Wine Country</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>R</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Amy Poehler,  Maya Rudolph,  Ana Gasteyer,  R...</td>\n",
       "      <td>Amy Poehler</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.4/10</td>\n",
       "      <td>103 minutes</td>\n",
       "      <td>80194950</td>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>When longtime friends meet up for a wine-soake...</td>\n",
       "      <td>English</td>\n",
       "      <td>[longtime, friend, meet, winesoaked, birthday,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>Love and Shukla</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://occ-0-114-116.1.nflxso.net/art/498c6/2...</td>\n",
       "      <td>https://occ-0-114-116.1.nflxso.net/art/498c6/2...</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Saharsh Kumar Shukla,  Taneea Rajawat,  Hima ...</td>\n",
       "      <td>Jatla Siddartha</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.3/10</td>\n",
       "      <td>110 minutes</td>\n",
       "      <td>81013710</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>A sexually inexperienced rickshaw driver strug...</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>[sexually, inexperienced, rickshaw, driver, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>Khido Khundi</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://occ-0-116-114.1.nflxso.net/art/effe0/d...</td>\n",
       "      <td>https://occ-0-116-114.1.nflxso.net/art/effe0/d...</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Ranjit Bawa,  Mandy Takhar,  Manav Vij,  Elna...</td>\n",
       "      <td>Rohit Jugraj</td>\n",
       "      <td>[]</td>\n",
       "      <td>6.5/10</td>\n",
       "      <td>150 minutes</td>\n",
       "      <td>81024696</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>An embittered former hockey star must engage w...</td>\n",
       "      <td>Panjabi</td>\n",
       "      <td>[embittered, former, hockey, star, must, engag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Benchwarmers 2: Breaking Balls</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>SuperHD</td>\n",
       "      <td>[Chris Klein,  Jon Lovitz,  Chelsey Reist,  Lo...</td>\n",
       "      <td>Jon Rosenbaum</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>90 minutes</td>\n",
       "      <td>81038225</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>A rookie lawyer with an emasculating past in b...</td>\n",
       "      <td>English</td>\n",
       "      <td>[rookie, lawyer, emasculating, past, baseball,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2917 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title   type titlereleased  \\\n",
       "3607                 Whose Streets?   Movie          2017   \n",
       "2527                       Salaakhen  Movie          1975   \n",
       "882                     Echcharikkai  Movie          2018   \n",
       "1126                            Girl  Movie          2018   \n",
       "682                        Cook Off   Movie          2017   \n",
       "...                              ...    ...           ...   \n",
       "3184                 The Pixar Story  Movie          2007   \n",
       "3619                    Wine Country  Movie          2019   \n",
       "1724                 Love and Shukla  Movie          2017   \n",
       "1576                    Khido Khundi  Movie          2018   \n",
       "387   Benchwarmers 2: Breaking Balls  Movie          2019   \n",
       "\n",
       "                                        image_landscape  \\\n",
       "3607  https://www.whats-on-netflix.com/wp-content/up...   \n",
       "2527  https://occ-0-114-116.1.nflxso.net/art/7e232/9...   \n",
       "882   https://occ-0-1722-1723.1.nflxso.net/art/8be71...   \n",
       "1126  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...   \n",
       "682   https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   \n",
       "...                                                 ...   \n",
       "3184  https://occ-0-1722-1723.1.nflxso.net/art/66734...   \n",
       "3619  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...   \n",
       "1724  https://occ-0-114-116.1.nflxso.net/art/498c6/2...   \n",
       "1576  https://occ-0-116-114.1.nflxso.net/art/effe0/d...   \n",
       "387   https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...   \n",
       "\n",
       "                                         image_portrait rating  quality  \\\n",
       "3607  https://www.whats-on-netflix.com/wp-content/up...      R  SuperHD   \n",
       "2527  https://occ-0-114-116.1.nflxso.net/art/7e232/9...  TV-14  SuperHD   \n",
       "882   https://occ-0-1722-1723.1.nflxso.net/art/8be71...  TV-14  SuperHD   \n",
       "1126  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...      R  SuperHD   \n",
       "682   https://occ-0-1722-1723.1.nflxso.net/dnm/api/v...   TV-G  SuperHD   \n",
       "...                                                 ...    ...      ...   \n",
       "3184  https://occ-0-1722-1723.1.nflxso.net/art/66734...      G  SuperHD   \n",
       "3619  https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...      R  SuperHD   \n",
       "1724  https://occ-0-114-116.1.nflxso.net/art/498c6/2...  TV-MA  SuperHD   \n",
       "1576  https://occ-0-116-114.1.nflxso.net/art/effe0/d...  TV-14  SuperHD   \n",
       "387   https://occ-0-1723-1722.1.nflxso.net/dnm/api/v...  PG-13  SuperHD   \n",
       "\n",
       "                                                 actors  \\\n",
       "3607  [Lezley McSpadden,  Michael Brown Sr.,  David ...   \n",
       "2527  [Shashi Kapoor,  Sulakshana Pandit,  Mehmood, ...   \n",
       "882   [Sathyaraj,  Varalakshmi Sarathkumar,  Kishore...   \n",
       "1126  [Katelijne Damen,  Oliver Bodart,  Magali Elal...   \n",
       "682   [Tendaiishe Chitima,  Tomas Brickhill,  Chirik...   \n",
       "...                                                 ...   \n",
       "3184                                      [Stacy Keach]   \n",
       "3619  [Amy Poehler,  Maya Rudolph,  Ana Gasteyer,  R...   \n",
       "1724  [Saharsh Kumar Shukla,  Taneea Rajawat,  Hima ...   \n",
       "1576  [Ranjit Bawa,  Mandy Takhar,  Manav Vij,  Elna...   \n",
       "387   [Chris Klein,  Jon Lovitz,  Chelsey Reist,  Lo...   \n",
       "\n",
       "                                      director            category    imdb  \\\n",
       "3607  Sabaah Folayan, Damon Davis(co-director)       [Documentary]    None   \n",
       "2527                                 A. Salaam                  []  5.3/10   \n",
       "882                                     Sarjun                  []  6.5/10   \n",
       "1126                               Lukas Dhont                  []  7.2/10   \n",
       "682                            Tomas Brickhill  [Comedy,  Romance]  6.4/10   \n",
       "...                                        ...                 ...     ...   \n",
       "3184                             Leslie Iwerks                  []  7.8/10   \n",
       "3619                               Amy Poehler                  []  5.4/10   \n",
       "1724                           Jatla Siddartha                  []  7.3/10   \n",
       "1576                              Rohit Jugraj                  []  6.5/10   \n",
       "387                              Jon Rosenbaum                  []           \n",
       "\n",
       "          runtime  netflixid date_released  \\\n",
       "3607      102 min   80168085    2020-11-16   \n",
       "2527  133 minutes   80158479    2017-04-01   \n",
       "882   126 minutes   81045065    2019-01-15   \n",
       "1126  105 minutes   81004374    2019-03-15   \n",
       "682       101 min   81273196    2020-06-01   \n",
       "...           ...        ...           ...   \n",
       "3184   88 minutes   70083532    2018-11-18   \n",
       "3619  103 minutes   80194950    2019-05-10   \n",
       "1724  110 minutes   81013710    2018-09-01   \n",
       "1576  150 minutes   81024696    2018-10-01   \n",
       "387    90 minutes   81038225    2019-12-31   \n",
       "\n",
       "                                            description language  \\\n",
       "3607  Powered by activists and leaders, this documen...  English   \n",
       "2527  Two close childhood friends take drastically d...    Hindi   \n",
       "882   After kidnapping a millionaire’s daughter, two...    Tamil   \n",
       "1126  Fifteen-year-old ballet dancer Lara faces phys...   French   \n",
       "682   Yearning for a better life, a single mother wi...  English   \n",
       "...                                                 ...      ...   \n",
       "3184  Go behind the scenes at Pixar Animation Studio...  English   \n",
       "3619  When longtime friends meet up for a wine-soake...  English   \n",
       "1724  A sexually inexperienced rickshaw driver strug...    Hindi   \n",
       "1576  An embittered former hockey star must engage w...  Panjabi   \n",
       "387   A rookie lawyer with an emasculating past in b...  English   \n",
       "\n",
       "                                      description_clean  \n",
       "3607  [powered, activist, leader, documentary, follo...  \n",
       "2527  [two, close, childhood, friend, take, drastica...  \n",
       "882   [kidnapping, millionaire, daughter, two, men, ...  \n",
       "1126  [fifteenyearold, ballet, dancer, lara, face, p...  \n",
       "682   [yearning, better, life, single, mother, passi...  \n",
       "...                                                 ...  \n",
       "3184  [go, behind, scene, pixar, animation, studio, ...  \n",
       "3619  [longtime, friend, meet, winesoaked, birthday,...  \n",
       "1724  [sexually, inexperienced, rickshaw, driver, st...  \n",
       "1576  [embittered, former, hockey, star, must, engag...  \n",
       "387   [rookie, lawyer, emasculating, past, baseball,...  \n",
       "\n",
       "[2917 rows x 17 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(content, test_size=0.5)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ebe04",
   "metadata": {},
   "source": [
    "## Bit of exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3210febf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# TV shows tragically don't list # of seasons or episodes\n",
    "\n",
    "content.groupby(['language']).title.count().sort_values(ascending=False)[0:50]\n",
    "# English is most common language by far\n",
    "# 34/8000 have no language at all\n",
    "\n",
    "content.loc[content.language.isnull()]\n",
    "content.loc[content.language == '']\n",
    "# Content without languages doesn't seem to follow any specific pattern\n",
    "\n",
    "content.groupby(['rating']).title.count().sort_values(ascending=False)[0:50]\n",
    "# 3.7k movies, 3.2 TV shows\n",
    "\n",
    "content.groupby(['type']).title.count().sort_values(ascending=False)[0:50]\n",
    "# 3.7k movies, 3.2 TV shows\n",
    "\n",
    "\n",
    "# content.dtypes\n",
    "# content[[\"title\"]] = content[[\"title\"]].astype(str)\n",
    "\n",
    "content.groupby(['rating','language']).title.count().sort_values(ascending=False)[0:50]\n",
    "content.groupby(['rating']).title.count().sort_values(ascending=False)[0:50]\n",
    "# ~25% of movies are Mature (2.5k) followed by TV-14 (1523)\n",
    "\n",
    "\n",
    "# content.head()\n",
    "\n",
    "\n",
    "content_by_cat = content.explode('category').reset_index(drop=True)\n",
    "content_by_cat.category[0:5].dtypes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
